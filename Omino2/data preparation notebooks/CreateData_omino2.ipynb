{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "CreateData_omino2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "457d1135"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from pyhdf.SD import SD, SDC\n",
        "import os\n",
        "import math\n",
        "import datetime as dt\n",
        "import h5py"
      ],
      "id": "457d1135",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b9380ad"
      },
      "source": [
        "GRANULES_PATH=\"omino2/OMNO2dv003/\" #path to OMNO2dv003 data\n",
        "OUTPUT_PATH=\"data/\" #path to store csv files\n",
        "LOCATION_FILE = 'geonames-all-cities-with-a-population-1000-3.csv' #path to cities data \n",
        "WEEK_MAPPINGS = 'data/week_mappings_omino2.csv' #path to week mappings \n",
        "week_data = pd.read_csv(WEEK_MAPPINGS)\n",
        "week_data=week_data.set_index(\"week\")[\"granules\"].to_dict()\n",
        "for week in week_data:\n",
        "    week_data[week]=week_data[week].split(\"#\")"
      ],
      "id": "7b9380ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88cc680e"
      },
      "source": [
        "metrics={}\n",
        "metrics[\"ColumnAmountNO2\"]=\"/HDFEOS/GRIDS/ColumnAmountNO2/Data Fields/ColumnAmountNO2\"\n",
        "metrics[\"ColumnAmountNO2CloudScreened\"]=\"/HDFEOS/GRIDS/ColumnAmountNO2/Data Fields/ColumnAmountNO2CloudScreened\"\n",
        "metrics[\"ColumnAmountNO2Trop\"]=\"/HDFEOS/GRIDS/ColumnAmountNO2/Data Fields/ColumnAmountNO2Trop\"\n",
        "metrics[\"ColumnAmountNO2TropCloudScreened\"]=\"/HDFEOS/GRIDS/ColumnAmountNO2/Data Fields/ColumnAmountNO2TropCloudScreened\"\n",
        "#metrics[\"Weight\"]=\"HDFEOS/GRIDS/ColumnAmountNO2/Data Fields/Weight\"\n",
        "weight_path=\"HDFEOS/GRIDS/ColumnAmountNO2/Data Fields/Weight\""
      ],
      "id": "88cc680e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd675e67"
      },
      "source": [
        "degree=0.25"
      ],
      "id": "bd675e67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6717b9f"
      },
      "source": [
        "fp=open(LOCATION_FILE,\"r\")\n",
        "evrythng=fp.readlines()\n",
        "fp.close()\n",
        "locations=set()\n",
        "for line in evrythng[1:]:\n",
        "    line=line.split(\"\\n\")[0].split(\";\")\n",
        "    [lat,long]=line[-1].split(\",\")\n",
        "    if degree==1:\n",
        "        lat=min(math.ceil(float(lat)),90.0)-0.5\n",
        "        long=min(math.ceil(float(long)),180.0)-0.5\n",
        "    elif degree==0.05:\n",
        "        lat=round(90-(int((90-float(lat))/0.05)*0.05+0.025),3)\n",
        "        long=round(180-(int((180-float(long))/0.05)*0.05+0.025),3)\n",
        "    elif degree==0.25:\n",
        "        lat=round(90-(int((90-float(lat))/0.25)*0.25+0.125),3)\n",
        "        long=round(180-(int((180-float(long))/0.25)*0.25+0.125),3)\n",
        "    else:\n",
        "        print(\"wrong degree resolution provided!\")\n",
        "    locations.add((lat,long))"
      ],
      "id": "f6717b9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2308801f"
      },
      "source": [
        "def get_indices(location):\n",
        "    (lat,long)=location\n",
        "    if degree==1:\n",
        "        lat_start_index=int((90-lat-0.5)*4)\n",
        "        lat_end_index=lat_start_index+4-1\n",
        "        long_start_index=int((long-0.5+180)*4)\n",
        "        long_end_index=long_start_index+4-1\n",
        "    elif degree==0.25:\n",
        "        lat_start_index=round(((90-lat-0.125)/0.25)*1)\n",
        "        lat_end_index=lat_start_index+1-1\n",
        "        long_start_index=round(((long-0.125+180)/0.25)*1)\n",
        "        long_end_index=long_start_index+1-1\n",
        "    lat_range=(lat_start_index,lat_end_index)\n",
        "    long_range=(long_start_index,long_end_index)\n",
        "    return [lat_range,long_range]"
      ],
      "id": "2308801f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "40116aab",
        "outputId": "ef3c4fab-819c-4f30-969d-e2323dadeb15"
      },
      "source": [
        "OUTPUT_FILENAME=OUTPUT_PATH+\"indian_cities_\"+str(degree)+\"degx\"+str(degree)+\"deg_omino2.csv\"\n",
        "fp=open(OUTPUT_FILENAME,\"w\")\n",
        "fp.write(\",\".join([\"location\",\"week\",\"metric\",\"mean\"])+\"\\n\")\n",
        "fp.close()\n",
        "for week in week_data:\n",
        "    print(week)\n",
        "    week_metric_data={}\n",
        "    for metric in metrics:\n",
        "        week_metric_data[metric]={}\n",
        "    for granule in week_data[week]:\n",
        "        f=h5py.File(GRANULES_PATH+granule, \"r\")\n",
        "        for metric in metrics:\n",
        "            metric_data=np.array(f[metrics[metric]])\n",
        "            weight_data=np.array(f[weight_path])\n",
        "            for location in locations:\n",
        "                indices=get_indices(location)\n",
        "                [lat_range,long_range]=indices\n",
        "                temp=metric_data[lat_range[0]:lat_range[1]+1,long_range[0]:long_range[1]+1]\n",
        "                weights=weight_data[lat_range[0]:lat_range[1]+1,long_range[0]:long_range[1]+1]\n",
        "                weights=weights[np.where(temp>-9999)]\n",
        "                if len(weights)<=0:\n",
        "                    continue\n",
        "                temp=temp[np.where(temp>-9999)]\n",
        "                if location not in week_metric_data[metric]:\n",
        "                    week_metric_data[metric][location]=[[],[]]\n",
        "                week_metric_data[metric][location][0]=np.append(week_metric_data[metric][location][0],temp)\n",
        "                week_metric_data[metric][location][1]=np.append(week_metric_data[metric][location][1],weights)\n",
        "    fp=open(OUTPUT_FILENAME,\"a\")\n",
        "    for metric in week_metric_data:\n",
        "        for location in week_metric_data[metric]:\n",
        "            avg=np.average(week_metric_data[metric][location][0],weights=week_metric_data[metric][location][1])\n",
        "            fp.write(\",\".join([str(location[0])+\"#\"+str(location[1]),week,metric]+[str(i) for i in [avg]])+\"\\n\")\n",
        "    fp.close()"
      ],
      "id": "40116aab",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2019.week1\n",
            "1.2019.week2\n",
            "1.2019.week3\n",
            "1.2019.week4\n",
            "2.2019.week1\n",
            "2.2019.week2\n",
            "2.2019.week3\n",
            "2.2019.week4\n",
            "3.2019.week1\n",
            "3.2019.week2\n",
            "3.2019.week3\n",
            "3.2019.week4\n",
            "4.2019.week1\n",
            "4.2019.week2\n",
            "4.2019.week3\n",
            "4.2019.week4\n",
            "5.2019.week1\n",
            "5.2019.week2\n",
            "5.2019.week3\n",
            "5.2019.week4\n",
            "6.2019.week1\n",
            "6.2019.week2\n",
            "6.2019.week3\n",
            "6.2019.week4\n",
            "7.2019.week1\n",
            "7.2019.week2\n",
            "7.2019.week3\n",
            "7.2019.week4\n",
            "8.2019.week1\n",
            "8.2019.week2\n",
            "8.2019.week3\n",
            "8.2019.week4\n",
            "9.2019.week1\n",
            "9.2019.week2\n",
            "9.2019.week3\n",
            "9.2019.week4\n",
            "10.2019.week1\n",
            "10.2019.week2\n",
            "10.2019.week3\n",
            "10.2019.week4\n",
            "11.2019.week1\n",
            "11.2019.week2\n",
            "11.2019.week3\n",
            "11.2019.week4\n",
            "12.2019.week1\n",
            "12.2019.week2\n",
            "12.2019.week3\n",
            "12.2019.week4\n",
            "1.2020.week1\n",
            "1.2020.week2\n",
            "1.2020.week3\n",
            "1.2020.week4\n",
            "2.2020.week1\n",
            "2.2020.week2\n",
            "2.2020.week3\n",
            "2.2020.week4\n",
            "3.2020.week1\n",
            "3.2020.week2\n",
            "3.2020.week3\n",
            "3.2020.week4\n",
            "4.2020.week1\n",
            "4.2020.week2\n",
            "4.2020.week3\n",
            "4.2020.week4\n",
            "5.2020.week1\n",
            "5.2020.week2\n",
            "5.2020.week3\n",
            "5.2020.week4\n",
            "6.2020.week1\n",
            "6.2020.week2\n",
            "6.2020.week3\n",
            "6.2020.week4\n",
            "7.2020.week1\n",
            "7.2020.week2\n",
            "7.2020.week3\n",
            "7.2020.week4\n",
            "8.2020.week1\n",
            "8.2020.week2\n",
            "8.2020.week3\n",
            "8.2020.week4\n",
            "9.2020.week1\n",
            "9.2020.week2\n",
            "9.2020.week3\n",
            "9.2020.week4\n",
            "10.2020.week1\n",
            "10.2020.week2\n",
            "10.2020.week3\n",
            "10.2020.week4\n",
            "11.2020.week1\n",
            "11.2020.week2\n",
            "11.2020.week3\n",
            "11.2020.week4\n",
            "12.2020.week1\n",
            "12.2020.week2\n",
            "12.2020.week3\n",
            "12.2020.week4\n",
            "1.2021.week1\n",
            "1.2021.week2\n",
            "1.2021.week3\n",
            "1.2021.week4\n",
            "2.2021.week1\n",
            "2.2021.week2\n",
            "2.2021.week3\n",
            "2.2021.week4\n",
            "3.2021.week1\n",
            "3.2021.week2\n",
            "3.2021.week3\n",
            "3.2021.week4\n",
            "4.2021.week1\n",
            "4.2021.week2\n",
            "4.2021.week3\n",
            "4.2021.week4\n",
            "5.2021.week1\n",
            "5.2021.week2\n",
            "5.2021.week3\n",
            "5.2021.week4\n",
            "6.2021.week1\n",
            "6.2021.week2\n",
            "6.2021.week3\n",
            "6.2021.week4\n",
            "7.2021.week1\n",
            "7.2021.week2\n",
            "7.2021.week3\n",
            "7.2021.week4\n",
            "8.2021.week1\n",
            "8.2021.week2\n",
            "8.2021.week3\n",
            "8.2021.week4\n",
            "9.2021.week1\n",
            "9.2021.week2\n",
            "9.2021.week3\n",
            "9.2021.week4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44c085c3"
      },
      "source": [
        ""
      ],
      "id": "44c085c3",
      "execution_count": null,
      "outputs": []
    }
  ]
}