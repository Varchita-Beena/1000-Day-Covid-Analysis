{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "CreateData_1degx1deg_vegetation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0wYu5OVjg0U"
      },
      "source": [
        "# Extract data for desired metrics for 1x1 degree for vegetation\n",
        "# Dataset\n",
        "The MODIS vegetation index (VI) products will provide consistent, spatial and\n",
        "temporal comparisons of global vegetation conditions which will be used to monitor the Earth's terrestrial photosynthetic vegetation activity in support of phenologic, change detection, and biophysical interpretations. Gridded vegetation index maps depicting spatial and temporal variations in vegetation activity are derived at 16-day and monthly intervals for precise seasonal and interannual monitoring of the Earth’s vegetation.<br><br>\n",
        "The downloaded data is at 16-day gap and at 0.05x0.05 degree. This has almost 13 scientific datasets out which we are using only NDVI and EVI with valid range as -2000, 10000 and fill value as -3000<br><br>\n",
        "\n"
      ],
      "id": "R0wYu5OVjg0U"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a224aeb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from pyhdf.SD import SD, SDC\n",
        "import os\n",
        "import math"
      ],
      "id": "4a224aeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d306c4d5"
      },
      "source": [
        "GRANULES_PATH=\"vegetation/MOD13C1v061/\"\n",
        "OUTPUT_PATH=\"data/\"\n",
        "LOCATION_FILE = 'geonames-all-cities-with-a-population-1000-3.csv'\n",
        "WEEK_MAPPINGS = 'data/week_mappings_vegetation.csv'\n",
        "week_data = pd.read_csv(WEEK_MAPPINGS)\n",
        "week_data=week_data.set_index(\"week\")[\"granule\"].to_dict()"
      ],
      "id": "d306c4d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fe2d13"
      },
      "source": [
        "metrics=[\"CMG 0.05 Deg 16 days NDVI\",\"CMG 0.05 Deg 16 days EVI\"]"
      ],
      "id": "75fe2d13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXW0k1WOj6Sj"
      },
      "source": [
        "# Providing grid names to granules in terms of city from LOCATION_FILE.\n",
        "Horizontal resolution= 1°x1° degree (360x180)<br>\n",
        "Upper Left Point= -180.0, 90.0<br>\n",
        "Lower Right Point= 180.0, -90.0<br>\n",
        "The latitudes and longitudes of the grid box centers are provided in the data (LATITUDE, LONGITUDE). The upper left box center location is (89.5, -179.5) and the lower right box center location is (-89.5, +179.5). The spatial extent of the 1x1 degree grid spans the upper left (+90, -180) to lower right (-90, +180). The longitude value goes from -180 to 180 and latitude value goes from 90 to -90.<br><br>\n",
        "\n",
        "The grid's center is given as (latitude, longitude) in data. To map that to out city (latitude, longitude) from LOCATION_FILE do:<br>\n",
        "\n",
        "1. change latitude and longitude into float<br>\n",
        "2. Take the ceiling value using math library.<br>\n",
        "3. Subtract 0.5 value from both latitude and longitude.<br>\n",
        "4. To not cross the maximum value 90 for latitude and 180 for longitude, always take minimum between ceil latitude value and max latitude (180) and minimum between ceil value and max longitude value (90).<br><br>\n",
        "\n",
        "Say, we have (18.2, 22.7) to map. According to (lat, long) center values provided in data, this longitude value is in the grid [18, 19] and latitude value is in the grid [22, 23]. So the center should come as (lat, long) -> (18.5, 22.5). Therefore by using ceiling the value will be (18.2, 22.7) -> (19, 23). Then by subtracting 0.5, will have (19, 23) - > (18.5, 22.5)."
      ],
      "id": "eXW0k1WOj6Sj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48384c97"
      },
      "source": [
        "fp=open(LOCATION_FILE,\"r\")\n",
        "evrythng=fp.readlines()\n",
        "fp.close()\n",
        "locations=set()\n",
        "for line in evrythng[1:]:\n",
        "    line=line.split(\"\\n\")[0].split(\";\")\n",
        "    [lat,long]=line[-1].split(\",\")\n",
        "    lat=min(math.ceil(float(lat)),90.0)-0.5\n",
        "    long=min(math.ceil(float(long)),180.0)-0.5\n",
        "    locations.add((lat,long))"
      ],
      "id": "48384c97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXi8QOPqkCLU"
      },
      "source": [
        "# HDF File\n",
        "HDF file contains sub datasets of every metrics. To access the metrics of particular latitude and longitude, those latitudes and logitudes are also stored as datasets.<br><br>\n",
        "\n",
        "We have coordinates of 0.05 degree x 0.05 degree cities. Now we want metrics for these locations (for these latitudes and longitudes).<br>\n",
        "\n",
        "How to get (latitude, longitude) pair from data for out (latitude, longitude) pair (of cities data)?. The latitude is stored as 2D matrix and also the longitude. We will get lat_obj by selecting latitude and long_obj by selecting longitude.\n",
        "\n",
        "Let say we want NDVI metric at latitude x and longitude y (i.e. NDVI[x,y]).Run over all indices of latitude and longitude, extract latitude value from latitude matrix for latitude and longitude matrix. Same way extract longitude value from longitude matrix. Compare values with x, y. If matched then store them in location_indices dictionary with key as (x,y) and value as (latitude index, longitude index). Now any metric can be extracted with these location indices.\n",
        "\n",
        "\n",
        "Total latitude blocks (latitude indices) will be 3600 (90 to -90 with 0.05 as gride) and total longitude blocks (longitude indices) will be 7200 (-180 to 180 as 0.05 gride). The matrices for both latitude and longitude is 3600x7200. Run for loop over latitude range and longitude range, will go through all indices and get latitude and longitude, compare them with our reqiured latitude and longitude values. If matched store them in dictionary.<br><br>\n",
        "\n",
        "Say to change every index 1 in latitude(3600) as per 0.05 degree, multiply 1 with 0.05 -> 0.05, Subtract it from 90 (max value) and from 0.025 (center of gride) -> 89.925<br><br>\n",
        "\n",
        "Now here the only thing to look when 1 degree is to taken into consideration is that total number of 20 grids is needed to make 1 degree,length of the block will be 1 and center of grid/block will be 0.5\n",
        "\n",
        "# Preparing CSV file\n",
        "Csv file will have the following fields: location, week, metric, mean, sdev, min, max. This data will be made for 0.05 degree x 0.05 degree city.<br>\n",
        "\n",
        "At the end all the values read above are stored under respective columns in a csv file.<br><br>\n"
      ],
      "id": "nXi8QOPqkCLU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1358c4b9"
      },
      "source": [
        "location_indices={}\n",
        "for (lat,long) in locations:\n",
        "    location_indices[(lat,long)]=[]\n",
        "    for lat_index in range((90-math.ceil(lat))*20,(90-math.ceil(lat))*20+20):\n",
        "        for long_index in range((math.floor(long)+180)*20,(math.floor(long)+180)*20+20):\n",
        "            location_indices[(lat,long)].append((lat_index,long_index))"
      ],
      "id": "1358c4b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "635a58d4",
        "outputId": "3368791a-4bda-41a6-a3d4-f134c450ac35"
      },
      "source": [
        "OUTPUT_FILENAME=OUTPUT_PATH+\"indian_cities_1degx1deg_vegetation.csv\"\n",
        "fp=open(OUTPUT_FILENAME,\"w\")\n",
        "fp.write(\",\".join([\"location\",\"week\",\"metric\",\"mean\",\"sdev\"])+\"\\n\")\n",
        "fp.close()\n",
        "for week in week_data:\n",
        "    print(week)\n",
        "    data=[]\n",
        "    granule=week_data[week]\n",
        "    hdf = SD(GRANULES_PATH+granule, SDC.READ)\n",
        "    \n",
        "    for metric in metrics:\n",
        "        metric_obj=hdf.select(metric)\n",
        "        metric_data=metric_obj.get()\n",
        "        \n",
        "        for location in location_indices:\n",
        "            vector=[]\n",
        "            for (lat_index,long_index) in location_indices[location]:\n",
        "                value=metric_data[lat_index,long_index]\n",
        "                if value>-3000:\n",
        "                    vector.append(value)\n",
        "            if len(vector)>0:\n",
        "                data.append([\"#\".join([str(i) for i in location]),week,metric,round(np.mean(vector)),round(np.std(vector))])\n",
        "            else:\n",
        "                data.append([\"#\".join([str(i) for i in location]),week,metric,-3000,-3000])\n",
        "    fp=open(OUTPUT_FILENAME,\"a\")\n",
        "    for vector in data:\n",
        "        fp.write(\",\".join([str(i) for i in vector])+\"\\n\")\n",
        "    fp.close()"
      ],
      "id": "635a58d4",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2019.week1\n",
            "1.2019.week2\n",
            "2.2019.week1\n",
            "2.2019.week2\n",
            "3.2019.week1\n",
            "3.2019.week2\n",
            "4.2019.week1\n",
            "4.2019.week2\n",
            "5.2019.week1\n",
            "5.2019.week2\n",
            "6.2019.week1\n",
            "6.2019.week2\n",
            "7.2019.week2\n",
            "8.2019.week1\n",
            "8.2019.week2\n",
            "9.2019.week1\n",
            "9.2019.week2\n",
            "10.2019.week1\n",
            "10.2019.week2\n",
            "11.2019.week1\n",
            "11.2019.week2\n",
            "12.2019.week1\n",
            "12.2019.week2\n",
            "1.2020.week1\n",
            "1.2020.week2\n",
            "2.2020.week1\n",
            "2.2020.week2\n",
            "3.2020.week1\n",
            "3.2020.week2\n",
            "4.2020.week1\n",
            "4.2020.week2\n",
            "5.2020.week1\n",
            "5.2020.week2\n",
            "6.2020.week1\n",
            "6.2020.week2\n",
            "7.2020.week1\n",
            "8.2020.week1\n",
            "8.2020.week2\n",
            "9.2020.week1\n",
            "9.2020.week2\n",
            "10.2020.week1\n",
            "10.2020.week2\n",
            "11.2020.week1\n",
            "11.2020.week2\n",
            "12.2020.week1\n",
            "12.2020.week2\n",
            "1.2021.week1\n",
            "1.2021.week2\n",
            "2.2021.week1\n",
            "2.2021.week2\n",
            "3.2021.week1\n",
            "3.2021.week2\n",
            "4.2021.week1\n",
            "4.2021.week2\n",
            "5.2021.week1\n",
            "5.2021.week2\n",
            "6.2021.week1\n",
            "6.2021.week2\n",
            "7.2021.week2\n",
            "8.2021.week1\n",
            "8.2021.week2\n",
            "9.2021.week1\n",
            "9.2021.week2\n",
            "10.2021.week1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "310d9946"
      },
      "source": [
        ""
      ],
      "id": "310d9946",
      "execution_count": null,
      "outputs": []
    }
  ]
}
