{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "CreateData_0.25degx0.25deg_vegetation.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJWi6v_bf8Rl"
      },
      "source": [
        "# Extract data for desired metrics for 0.25x0.25 degree for vegetation\n",
        "# Dataset\n",
        "The MODIS vegetation index (VI) products will provide consistent, spatial and\n",
        "temporal comparisons of global vegetation conditions which will be used to monitor the Earth's terrestrial photosynthetic vegetation activity in support of phenologic, change detection, and biophysical interpretations. Gridded vegetation index maps depicting spatial and temporal variations in vegetation activity are derived at 16-day and monthly intervals for precise seasonal and interannual monitoring of the Earth’s vegetation.<br><br>\n",
        "The downloaded data is at 16-day gap and at 0.05x0.05 degree. This has almost 13 scientific datasets out which we are using only NDVI and EVI with valid range as -2000, 10000 and fill value as -3000<br><br>\n",
        "\n"
      ],
      "id": "EJWi6v_bf8Rl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a224aeb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from pyhdf.SD import SD, SDC\n",
        "import os\n",
        "import math"
      ],
      "id": "4a224aeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d306c4d5"
      },
      "source": [
        "GRANULES_PATH=\"\" #path where hdf files of MOD13C1v061 is stored.\n",
        "OUTPUT_PATH=\"data/\" ##where you want to store the output file\n",
        "LOCATION_FILE = '' #path of files with details of cities with latitude, longitude, population, elevation etc (geonames-all-cities-with-a-population-1000-3.csv).\n",
        "WEEK_MAPPINGS = 'data/week_mappings_vegetation.csv' ##the week mappings file made from GenerateWeekMappings_vegetation.ipynb. This tells us about which granule falls under which week.\n",
        "week_data = pd.read_csv(WEEK_MAPPINGS)\n",
        "week_data=week_data.set_index(\"week\")[\"granule\"].to_dict()"
      ],
      "id": "d306c4d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fe2d13"
      },
      "source": [
        "metrics=[\"CMG 0.05 Deg 16 days NDVI\",\"CMG 0.05 Deg 16 days EVI\"]"
      ],
      "id": "75fe2d13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73ZliY1FgdOG"
      },
      "source": [
        "# Providing grid names to granules in terms of city from LOCATION_FILE.\n",
        "Horizontal resolution= 1°x1° degree (360x180)<br>\n",
        "Upper Left Point= -180.0, 90.0<br>\n",
        "Lower Right Point= 180.0, -90.0<br>\n",
        "The latitudes and longitudes of the grid box centers are provided in the data (LATITUDE, LONGITUDE). The upper left box center location is (89.5, -179.5) and the lower right box center location is (-89.5, +179.5). The spatial extent of the 1x1 degree grid spans the upper left (+90, -180) to lower right (-90, +180). The longitude value goes from -180 to 180 and latitude value goes from 90 to -90.<br><br>\n",
        "\n",
        "The grid's center is given as (latitude, longitude) in data. To map that to out city (latitude, longitude) from LOCATION_FILE do:<br>\n",
        "\n",
        "1. change latitude and longitude into float<br>\n",
        "2. Subrtact it from 90 for latitude and from 180 for longitude divide by 0.05 and change it to integer.<br>\n",
        "3. Divide by main resolution 0.05,multiply by main resolution 0.05\n",
        "4. Subtract from max value and add the half of the grid 0.025 and round upto 3 places<br>\n",
        "\n",
        "\n",
        "Say, we have (89.86) latitude. According to (lat, long) center values provided in data, this latitude value is in the grid [89.9, 89.85]. So the center should come as (lat) -> (0.89.875). So the intuition behind using this is, first we have to find how much away we have travelled from max value (here, how much 0.111 is away from 90 by (90 - 89.86 -> 0.14)). How many grids are we away in terms of 0.05 i.e 0.14 / 0.05, change it to integer -> 2. Find how much away we are from 90 in terms of 0.05 by multiplying it with 0.5 -> 0.1, i.e. we are at the center of the previous grid and by add 0.025 (center of 0.05 grid) and subtracting it from 90 we will get center of the grid where our latitude belongs i.e. 89.875<br><br>\n",
        "\n",
        "Now here the only thing to look when 0.25 degree is to taken into consideration is that total number of 5 grids is needed to make 0.25 degree,length of the block will be 0.25 and center of grid/block will be 0.125"
      ],
      "id": "73ZliY1FgdOG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48384c97"
      },
      "source": [
        "fp=open(LOCATION_FILE,\"r\")\n",
        "evrythng=fp.readlines()\n",
        "fp.close()\n",
        "locations=set()\n",
        "for line in evrythng[1:]:\n",
        "    line=line.split(\"\\n\")[0].split(\";\")\n",
        "    [lat,long]=line[-1].split(\",\")\n",
        "    lat=round(90-(int((90-float(lat))/0.25)*0.25+0.125),3)\n",
        "    long=round(180-(int((180-float(long))/0.25)*0.25+0.125),3)\n",
        "    locations.add((lat,long))"
      ],
      "id": "48384c97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6KCrkY1ghM4"
      },
      "source": [
        "# HDF File\n",
        "HDF file contains sub datasets of every metrics. To access the metrics of particular latitude and longitude, those latitudes and logitudes are also stored as datasets.<br><br>\n",
        "\n",
        "We have coordinates of 0.05 degree x 0.05 degree cities. Now we want metrics for these locations (for these latitudes and longitudes).<br>\n",
        "\n",
        "How to get (latitude, longitude) pair from data for out (latitude, longitude) pair (of cities data)?. The latitude is stored as 2D matrix and also the longitude. We will get lat_obj by selecting latitude and long_obj by selecting longitude.\n",
        "\n",
        "Let say we want NDVI metric at latitude x and longitude y (i.e. NDVI[x,y]).Run over all indices of latitude and longitude, extract latitude value from latitude matrix for latitude and longitude matrix. Same way extract longitude value from longitude matrix. Compare values with x, y. If matched then store them in location_indices dictionary with key as (x,y) and value as (latitude index, longitude index). Now any metric can be extracted with these location indices.\n",
        "\n",
        "\n",
        "Total latitude blocks (latitude indices) will be 3600 (90 to -90 with 0.05 as gride) and total longitude blocks (longitude indices) will be 7200 (-180 to 180 as 0.05 gride). The matrices for both latitude and longitude is 3600x7200. Run for loop over latitude range and longitude range, will go through all indices and get latitude and longitude, compare them with our reqiured latitude and longitude values. If matched store them in dictionary.<br><br>\n",
        "\n",
        "Say to change every index 1 in latitude(3600) as per 0.05 degree, multiply 1 with 0.05 -> 0.05, Subtract it from 90 (max value) and from 0.025 (center of gride) -> 89.925<br><br>\n",
        "\n",
        "Now here the only thing to look when 0.25 degree is to taken into consideration is that total number of 5 grids is needed to make 0.25 degree,length of the block will be 0.25 and center of grid/block will be 0.125\n",
        "\n",
        "# Preparing CSV file\n",
        "Csv file will have the following fields: location, week, metric, mean, sdev, min, max. This data will be made for 0.05 degree x 0.05 degree city.<br>\n",
        "\n",
        "At the end all the values read above are stored under respective columns in a csv file.<br><br>\n"
      ],
      "id": "c6KCrkY1ghM4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1358c4b9"
      },
      "source": [
        "def get_indices(location):\n",
        "    (lat,long)=location\n",
        "    lat_start_index=round(((90-lat-0.125)/0.25)*5)\n",
        "    lat_end_index=lat_start_index+5-1\n",
        "    long_start_index=round(((long-0.125+180)/0.25)*5)\n",
        "    long_end_index=long_start_index+5-1\n",
        "    lat_range=(lat_start_index,lat_end_index)\n",
        "    long_range=(long_start_index,long_end_index)\n",
        "    return [lat_range,long_range]"
      ],
      "id": "1358c4b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "635a58d4",
        "outputId": "64bfd826-3745-496d-c6d1-2c579188c4d1"
      },
      "source": [
        "OUTPUT_FILENAME=OUTPUT_PATH+\"indian_cities_0.25degx0.25deg_vegetation.csv\"\n",
        "fp=open(OUTPUT_FILENAME,\"w\")\n",
        "fp.write(\",\".join([\"location\",\"week\",\"metric\",\"mean\",\"sdev\"])+\"\\n\")\n",
        "fp.close()\n",
        "for week in week_data:\n",
        "    print(week)\n",
        "    data=[]\n",
        "    granule=week_data[week]\n",
        "    hdf = SD(GRANULES_PATH+granule, SDC.READ)\n",
        "    \n",
        "    for metric in metrics:\n",
        "        metric_obj=hdf.select(metric)\n",
        "        metric_data=metric_obj.get()\n",
        "        \n",
        "        for location in locations:\n",
        "            [lat_range,long_range]=get_indices(location)\n",
        "            temp=metric_data[lat_range[0]:lat_range[1]+1,long_range[0]:long_range[1]+1]\n",
        "            temp=temp[np.where(temp>-3000)]\n",
        "            if len(temp)<=0:\n",
        "                data.append([\"#\".join([str(i) for i in location]),week,metric,-3000,-3000])\n",
        "            else:\n",
        "                data.append([\"#\".join([str(i) for i in location]),week,metric,round(np.mean(temp)),round(np.std(temp))]) \n",
        "    fp=open(OUTPUT_FILENAME,\"a\")\n",
        "    for vector in data:\n",
        "        fp.write(\",\".join([str(i) for i in vector])+\"\\n\")\n",
        "    fp.close()"
      ],
      "id": "635a58d4",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2019.week1\n",
            "1.2019.week2\n",
            "2.2019.week1\n",
            "2.2019.week2\n",
            "3.2019.week1\n",
            "3.2019.week2\n",
            "4.2019.week1\n",
            "4.2019.week2\n",
            "5.2019.week1\n",
            "5.2019.week2\n",
            "6.2019.week1\n",
            "6.2019.week2\n",
            "7.2019.week2\n",
            "8.2019.week1\n",
            "8.2019.week2\n",
            "9.2019.week1\n",
            "9.2019.week2\n",
            "10.2019.week1\n",
            "10.2019.week2\n",
            "11.2019.week1\n",
            "11.2019.week2\n",
            "12.2019.week1\n",
            "12.2019.week2\n",
            "1.2020.week1\n",
            "1.2020.week2\n",
            "2.2020.week1\n",
            "2.2020.week2\n",
            "3.2020.week1\n",
            "3.2020.week2\n",
            "4.2020.week1\n",
            "4.2020.week2\n",
            "5.2020.week1\n",
            "5.2020.week2\n",
            "6.2020.week1\n",
            "6.2020.week2\n",
            "7.2020.week1\n",
            "8.2020.week1\n",
            "8.2020.week2\n",
            "9.2020.week1\n",
            "9.2020.week2\n",
            "10.2020.week1\n",
            "10.2020.week2\n",
            "11.2020.week1\n",
            "11.2020.week2\n",
            "12.2020.week1\n",
            "12.2020.week2\n",
            "1.2021.week1\n",
            "1.2021.week2\n",
            "2.2021.week1\n",
            "2.2021.week2\n",
            "3.2021.week1\n",
            "3.2021.week2\n",
            "4.2021.week1\n",
            "4.2021.week2\n",
            "5.2021.week1\n",
            "5.2021.week2\n",
            "6.2021.week1\n",
            "6.2021.week2\n",
            "7.2021.week2\n",
            "8.2021.week1\n",
            "8.2021.week2\n",
            "9.2021.week1\n",
            "9.2021.week2\n",
            "10.2021.week1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "310d9946"
      },
      "source": [
        ""
      ],
      "id": "310d9946",
      "execution_count": null,
      "outputs": []
    }
  ]
}