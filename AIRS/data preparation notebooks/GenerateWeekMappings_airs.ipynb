{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "GenerateWeekMappings_airs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWpcSipIRl03"
      },
      "source": [
        "**We have 8-day data from AIRS.**"
      ],
      "id": "xWpcSipIRl03"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccb44904"
      },
      "source": [
        "import datetime as dt\n",
        "import os"
      ],
      "id": "ccb44904",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "604625bf"
      },
      "source": [
        "DATA_PATH='' #directory where AIRS2ST8 has been downloaded/stored.\"\n",
        "OUTPUT_PATH=\"data/\""
      ],
      "id": "604625bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW7jARCtxdmP"
      },
      "source": [
        "We have in total 123 granules. So each granules belongs to 8-day data from 01-01-2019 to 30-09-21. We have 123 granule names stored in granules."
      ],
      "id": "fW7jARCtxdmP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c8559b7",
        "outputId": "b6997943-ccde-4b2d-a3e9-18d13b2a29c8"
      },
      "source": [
        "granules=os.listdir(DATA_PATH)\n",
        "print(\"granules =\",len(granules))"
      ],
      "id": "3c8559b7",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "granules = 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdt1spUhyDbs"
      },
      "source": [
        "## Mapping criteria<br>\n",
        "We have to map each granule to weeks. Mapped into 4 weeks for each month. Here week represents 8-days. Which granule will map to which week is decided on the basis of number of days overlap. Minimum 4 days should be overlapped to map to a week. Once a granule is used it can not be used again.<br>\n",
        "week-1: dates 1 to 8<br>\n",
        "week-2: dates 9 to 16<br>\n",
        "week-3: dates 17 to 24<br>\n",
        "week-4: dates 25 to end.<br>"
      ],
      "id": "Xdt1spUhyDbs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76a0a79"
      },
      "source": [
        "week_length=8 #days\n",
        "n_weeks_per_month=4\n",
        "min_overlap=4 #days"
      ],
      "id": "d76a0a79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYRdYTvfy45N"
      },
      "source": [
        "## Example File Names\n",
        "8-Day Product Dec 3-10, 2009 processed using only AIRS radiances:<br>\n",
        "Name: AIRS.2009.12.03.L3.RetStd_IR008.v6.0.9.0.G2002123120634.hdf<br><br>\n",
        "### Making a dictionary with key as granule name and value as 8 dates that belong to that granule<br>\n",
        "Year, month and day is extracted from the above name as 2009, 12, 3.<br>\n",
        "Using datetime.date(2009,12,3) we will a date as 2009-12-03. These dates are stored are in dictionary (named granules_dates) as values for their granule names as keys.<br><br>\n",
        "For each in key(granule) in dictionary only one value is present(date extracted from granule name). So, continously next  7 dates are added in the values. So, for 2009-12-03 next 7 dates will be (2009-12-04, 2009-12-05, 2009-12-06, 2009-12-07, 2009-12-08, 2009-12-09, 2009-12-10). Hence, every key(granule name) will have list of 8 dates as value.\n",
        "\n",
        "\n"
      ],
      "id": "kYRdYTvfy45N"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91b2f300"
      },
      "source": [
        "granule_dates={}\n",
        "for granule in granules:\n",
        "    values=granule.split(\".\")\n",
        "    year=int(values[1])\n",
        "    month=int(values[2])\n",
        "    day=int(values[3])\n",
        "    date=dt.date(year,month,day)\n",
        "    granule_dates[granule]=[date]\n",
        "    for i in range(7):\n",
        "        date=date+dt.timedelta(days=1)\n",
        "        granule_dates[granule].append(date)"
      ],
      "id": "91b2f300",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_fEvguT22PX"
      },
      "source": [
        "## Making a dictionary with key as week and value as the dates falling that week<br>\n",
        "For loop over 3 years namely 2019, 2020, 2021, over 12 months i.e. 1 to 12 and over 4 weeks (weeks starting from 1) and day starting from 1st. (i.e. starting from 2019-01-01).<br><br>Making a dictionary (named week_dates) with keys as start of week and values as the days falling in that week. Fetching date after every 8 days for 4 times(4 weeks in a month) (say 2019-01-01, 2019-01-09, 2019-01-17, 2019-01-25).<br><br>The innermost loop is running from 0 to 7 as we have found 1 date in the last date. So, for every date extracted in the above step we are appending consecutive 7 more dates. The only one more constraint is all the dates should be of same month, as soon as month changes the innermost loop breaks, giving dates of same month only.<br><br> Finally the dictionary is made as say: Key = 1.2019.week1 and its value is [2019-01-01, 2019-01-02, 2019-01-03, 2019-01-04, 2019-01-05, 2019-01-06, 2019-01-07, 2019-01-08]"
      ],
      "id": "0_fEvguT22PX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d317bb61"
      },
      "source": [
        "week_dates={}\n",
        "months=[i+1 for i in range(12)]\n",
        "years=[2019,2020,2021]\n",
        "for year in years:\n",
        "    for month in months:\n",
        "        for week in range(1,n_weeks_per_month+1,1):\n",
        "            date=dt.date(year,month,1)+dt.timedelta(days=week_length*(week-1))\n",
        "            dates=[date]\n",
        "            for i in range(week_length-1):\n",
        "                new_date=date+dt.timedelta(days=1)\n",
        "                if new_date.month==date.month:\n",
        "                    dates.append(new_date)\n",
        "                    date=new_date\n",
        "                else:\n",
        "                    break\n",
        "            week_dates[str(month)+\".\"+str(year)+\".\"+\"week\"+str(week)]=dates                "
      ],
      "id": "d317bb61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeAsJy5_NjFz"
      },
      "source": [
        "## Making a dictionary \n",
        "Now we have week_dates dictionary with keys as name of week and values as the days falling in that week.<br>\n",
        "Another dictionary granule_dates with key as granule name and value as 8 dates that belong to that granule.<br><br>\n",
        "\n",
        "Now, Take intersection of dates stored in week_dates for evey week with dates stored in granule_dates for every granule. If minimum over lap is equal or more than 4 then put the total number of intersected dates as value in intersection dictionary with key as granule name.<br><br>\n",
        "If the length of intersection dictionary is equal or greater than 1 then put week as key in week_granule dictionary with value as max of zip of intersection values and keys. By this we will get the key (granule name) which has max number of intersection.<br><br> We want every granule to be used as once only hence the for loop is over unused granules using set intersection.\n",
        "\n"
      ],
      "id": "XeAsJy5_NjFz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa62b6db"
      },
      "source": [
        "week_granule={}\n",
        "for week in week_dates:\n",
        "    intersection={}\n",
        "    for granule in set(granules).difference(set(week_granule.values())):\n",
        "        value=len(set(week_dates[week]).intersection(granule_dates[granule]))\n",
        "        if value>=min_overlap:\n",
        "            intersection[granule]=value\n",
        "    if len(intersection)>=1:\n",
        "        week_granule[week]=max(zip(intersection.values(), intersection.keys()))[1]"
      ],
      "id": "fa62b6db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JcA85R4SPc6"
      },
      "source": [
        "## Making a csv file of week mappings\n",
        "File name week_mappings_airs.csv with columns week and granule, showing the mapping of which granule falls in which week. Use week_granule dictionary from above step which has key as week, store it in week column and its value (i.e. name of granule) under granule column."
      ],
      "id": "-JcA85R4SPc6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cfa6fe4"
      },
      "source": [
        "fp=open(OUTPUT_PATH+\"week_mappings_airs.csv\",\"w\")\n",
        "fp.write(\"week,granule\\n\")\n",
        "for week in week_granule:\n",
        "    fp.write(week+\",\"+week_granule[week]+\"\\n\")\n",
        "fp.close()"
      ],
      "id": "4cfa6fe4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90b45b09"
      },
      "source": [
        ""
      ],
      "id": "90b45b09",
      "execution_count": null,
      "outputs": []
    }
  ]
}
