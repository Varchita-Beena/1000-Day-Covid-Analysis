{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "CreateData_15days_lakes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSUGLhx8hvJp"
      },
      "source": [
        "**lakes data is made on 15-day interval**"
      ],
      "id": "vSUGLhx8hvJp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea2396e3"
      },
      "source": [
        "import datetime as dt\n",
        "import numpy as np"
      ],
      "id": "ea2396e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7724b36b"
      },
      "source": [
        "DATA_PATH=\"data/\" #path for lakes data\n",
        "OUTPUT_PATH=DATA_PATH# path to store 15-day data"
      ],
      "id": "7724b36b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2LCs38AjfAh"
      },
      "source": [
        "Each week = 15 days. So, 2 weeks a month."
      ],
      "id": "A2LCs38AjfAh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb3859a6"
      },
      "source": [
        "n_weeks_per_month=2\n",
        "week_length=15"
      ],
      "id": "cb3859a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Tp0SnskaXR"
      },
      "source": [
        "Data is made for years 2015 to 2021. <br>\n",
        "Week mapping is done by running a for loop for 7 years, 12 months and 2 weeks. Two dates are generated say 01-01-2019 and 16-01-2019. week_dates dictionary is made with key as start date (week name) and values as all the 15 dates falling for that week. "
      ],
      "id": "Y4Tp0SnskaXR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0154e01f"
      },
      "source": [
        "week_dates={}\n",
        "months=[i+1 for i in range(12)]\n",
        "years=[2015,2016,2017,2018,2019,2020,2021]\n",
        "for year in years:\n",
        "    for month in months:\n",
        "        for week in range(1,n_weeks_per_month+1,1):\n",
        "            date=dt.date(year,month,1)+dt.timedelta(days=week_length*(week-1))\n",
        "            dates=[date]\n",
        "            n_additions=week_length-1\n",
        "            if week==2:\n",
        "                n_additions+=1\n",
        "            for i in range(n_additions):\n",
        "                new_date=date+dt.timedelta(days=1)\n",
        "                if new_date.month==date.month:\n",
        "                    dates.append(new_date)\n",
        "                    date=new_date\n",
        "                else:\n",
        "                    break\n",
        "            week_dates[str(month)+\".\"+str(year)+\".\"+\"week\"+str(week)]=dates                "
      ],
      "id": "0154e01f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14a4dcd6"
      },
      "source": [
        "fp=open(DATA_PATH+\"lakes_data.csv\",\"r\")\n",
        "evrythng=fp.readlines()\n",
        "fp.close()\n",
        "data={}\n",
        "for line in evrythng[1:]:\n",
        "    line=line.split(\"\\n\")[0].split(\",\")\n",
        "    identifier=line[0]\n",
        "    [year,month,day]=line[1].split(\"-\")\n",
        "    date=dt.date(int(year),int(month),int(day))\n",
        "    level=float(line[2])\n",
        "    if identifier not in data:\n",
        "        data[identifier]={}\n",
        "    data[identifier][date]=level"
      ],
      "id": "14a4dcd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KheyoaOBlUJv"
      },
      "source": [
        "The 15-day week is made by taking the mean of values of 15 days"
      ],
      "id": "KheyoaOBlUJv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "70c8f638",
        "outputId": "0e2b0ec2-0664-4693-e69e-d765db769ce1"
      },
      "source": [
        "vectors=[]\n",
        "for week in week_dates:\n",
        "    print(week)\n",
        "    for identifier in data:\n",
        "        dates=set(week_dates[week]).intersection(set(data[identifier].keys()))\n",
        "        if len(dates)==0:\n",
        "            continue\n",
        "        values=[data[identifier][date] for date in dates]\n",
        "        vectors.append([identifier,week,\"water_level\",round(np.mean(values),2),round(np.std(values),2)])\n",
        "fp=open(OUTPUT_PATH+\"lakes_data_15days.csv\",\"w\")\n",
        "fp.write(\",\".join([\"lake_id\",\"week\",\"metric\",\"mean\",\"sdev\"])+\"\\n\")\n",
        "for vector in vectors:\n",
        "    fp.write(\",\".join([str(i) for i in vector])+\"\\n\")\n",
        "fp.close()"
      ],
      "id": "70c8f638",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2015.week1\n",
            "1.2015.week2\n",
            "2.2015.week1\n",
            "2.2015.week2\n",
            "3.2015.week1\n",
            "3.2015.week2\n",
            "4.2015.week1\n",
            "4.2015.week2\n",
            "5.2015.week1\n",
            "5.2015.week2\n",
            "6.2015.week1\n",
            "6.2015.week2\n",
            "7.2015.week1\n",
            "7.2015.week2\n",
            "8.2015.week1\n",
            "8.2015.week2\n",
            "9.2015.week1\n",
            "9.2015.week2\n",
            "10.2015.week1\n",
            "10.2015.week2\n",
            "11.2015.week1\n",
            "11.2015.week2\n",
            "12.2015.week1\n",
            "12.2015.week2\n",
            "1.2016.week1\n",
            "1.2016.week2\n",
            "2.2016.week1\n",
            "2.2016.week2\n",
            "3.2016.week1\n",
            "3.2016.week2\n",
            "4.2016.week1\n",
            "4.2016.week2\n",
            "5.2016.week1\n",
            "5.2016.week2\n",
            "6.2016.week1\n",
            "6.2016.week2\n",
            "7.2016.week1\n",
            "7.2016.week2\n",
            "8.2016.week1\n",
            "8.2016.week2\n",
            "9.2016.week1\n",
            "9.2016.week2\n",
            "10.2016.week1\n",
            "10.2016.week2\n",
            "11.2016.week1\n",
            "11.2016.week2\n",
            "12.2016.week1\n",
            "12.2016.week2\n",
            "1.2017.week1\n",
            "1.2017.week2\n",
            "2.2017.week1\n",
            "2.2017.week2\n",
            "3.2017.week1\n",
            "3.2017.week2\n",
            "4.2017.week1\n",
            "4.2017.week2\n",
            "5.2017.week1\n",
            "5.2017.week2\n",
            "6.2017.week1\n",
            "6.2017.week2\n",
            "7.2017.week1\n",
            "7.2017.week2\n",
            "8.2017.week1\n",
            "8.2017.week2\n",
            "9.2017.week1\n",
            "9.2017.week2\n",
            "10.2017.week1\n",
            "10.2017.week2\n",
            "11.2017.week1\n",
            "11.2017.week2\n",
            "12.2017.week1\n",
            "12.2017.week2\n",
            "1.2018.week1\n",
            "1.2018.week2\n",
            "2.2018.week1\n",
            "2.2018.week2\n",
            "3.2018.week1\n",
            "3.2018.week2\n",
            "4.2018.week1\n",
            "4.2018.week2\n",
            "5.2018.week1\n",
            "5.2018.week2\n",
            "6.2018.week1\n",
            "6.2018.week2\n",
            "7.2018.week1\n",
            "7.2018.week2\n",
            "8.2018.week1\n",
            "8.2018.week2\n",
            "9.2018.week1\n",
            "9.2018.week2\n",
            "10.2018.week1\n",
            "10.2018.week2\n",
            "11.2018.week1\n",
            "11.2018.week2\n",
            "12.2018.week1\n",
            "12.2018.week2\n",
            "1.2019.week1\n",
            "1.2019.week2\n",
            "2.2019.week1\n",
            "2.2019.week2\n",
            "3.2019.week1\n",
            "3.2019.week2\n",
            "4.2019.week1\n",
            "4.2019.week2\n",
            "5.2019.week1\n",
            "5.2019.week2\n",
            "6.2019.week1\n",
            "6.2019.week2\n",
            "7.2019.week1\n",
            "7.2019.week2\n",
            "8.2019.week1\n",
            "8.2019.week2\n",
            "9.2019.week1\n",
            "9.2019.week2\n",
            "10.2019.week1\n",
            "10.2019.week2\n",
            "11.2019.week1\n",
            "11.2019.week2\n",
            "12.2019.week1\n",
            "12.2019.week2\n",
            "1.2020.week1\n",
            "1.2020.week2\n",
            "2.2020.week1\n",
            "2.2020.week2\n",
            "3.2020.week1\n",
            "3.2020.week2\n",
            "4.2020.week1\n",
            "4.2020.week2\n",
            "5.2020.week1\n",
            "5.2020.week2\n",
            "6.2020.week1\n",
            "6.2020.week2\n",
            "7.2020.week1\n",
            "7.2020.week2\n",
            "8.2020.week1\n",
            "8.2020.week2\n",
            "9.2020.week1\n",
            "9.2020.week2\n",
            "10.2020.week1\n",
            "10.2020.week2\n",
            "11.2020.week1\n",
            "11.2020.week2\n",
            "12.2020.week1\n",
            "12.2020.week2\n",
            "1.2021.week1\n",
            "1.2021.week2\n",
            "2.2021.week1\n",
            "2.2021.week2\n",
            "3.2021.week1\n",
            "3.2021.week2\n",
            "4.2021.week1\n",
            "4.2021.week2\n",
            "5.2021.week1\n",
            "5.2021.week2\n",
            "6.2021.week1\n",
            "6.2021.week2\n",
            "7.2021.week1\n",
            "7.2021.week2\n",
            "8.2021.week1\n",
            "8.2021.week2\n",
            "9.2021.week1\n",
            "9.2021.week2\n",
            "10.2021.week1\n",
            "10.2021.week2\n",
            "11.2021.week1\n",
            "11.2021.week2\n",
            "12.2021.week1\n",
            "12.2021.week2\n"
          ]
        }
      ]
    }
  ]
}